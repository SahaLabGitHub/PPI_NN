{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training features shape: (503, 42)\n",
      "\n",
      "=== Checking Contini Test Set ===\n",
      " - Missing in test: {'resolution'}\n",
      " - Extra in test: set()\n",
      "‚ö†Ô∏è Large mean differences found in these features:\n",
      "                          Train Mean   Test Mean   Train Std    Test Std\n",
      "Sc                         0.693833   -0.229703    0.065129    0.875012\n",
      "Sc_int_area             1262.105788  398.649515  519.682554  492.507333\n",
      "dG_cross                 -69.399482  -22.880247   31.079032   27.212992\n",
      "dG_cross/dSASAx100        -3.141300   -1.534230    0.729421    1.808604\n",
      "dG_separated/dSASAx100    -2.735526  -20.077056    0.599319   28.473381\n",
      "dSASA_hphobic           1276.643257  558.079505  520.000152  492.542362\n",
      "dSASA_int               2208.100180  996.246183  838.217660  805.277054\n",
      "dSASA_polar              931.456923  438.166680  392.772897  327.593266\n",
      "per_residue_energy_int    -2.827811   -3.341849    0.484021    0.996970\n",
      "sc_value                   0.688660    0.415119    0.066578    0.352951\n",
      "side2_normalized          -2.664260   -9.002192    0.703853   10.056295\n",
      "resolution                 2.191590    0.000000    0.400688    0.000000\n",
      " - Scaled data example (train first row): [ 0.47010696  0.6403874  -1.14893922 -0.85337094  0.8951434 ]\n",
      "\n",
      "=== Checking Nanobody Test Set ===\n",
      " - Missing in test: {'resolution'}\n",
      " - Extra in test: set()\n",
      "‚ö†Ô∏è Large mean differences found in these features:\n",
      "                 Train Mean   Test Mean   Train Std    Test Std\n",
      "dSASA_hphobic  1276.643257  735.044432  520.000152  228.605237\n",
      "resolution        2.191590    0.000000    0.400688    0.000000\n",
      " - Scaled data example (train first row): [ 0.47010696  0.6403874  -1.14893922 -0.85337094  0.8951434 ]\n",
      "\n",
      "=== Checking PDBbind Test Set ===\n",
      " - Missing in test: {'resolution'}\n",
      " - Extra in test: set()\n",
      "‚ö†Ô∏è Large mean differences found in these features:\n",
      "             Train Mean  Test Mean  Train Std  Test Std\n",
      "Sc            0.693833   0.560111   0.065129  0.497062\n",
      "resolution    2.191590   0.000000   0.400688  0.000000\n",
      " - Scaled data example (train first row): [ 0.47010696  0.6403874  -1.14893922 -0.85337094  0.8951434 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ========= Paths =========\n",
    "train_csv = \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/Rueben_504.csv\"\n",
    "\n",
    "test_csvs = {\n",
    "    \"Contini\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/Contini_20_testset.csv\",\n",
    "    \"Nanobody\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/nanobody_testset.csv\",\n",
    "    \"PDBbind\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/PDBbind_testset.csv\"\n",
    "}\n",
    "\n",
    "# === Prepare train set ===\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_train[\"dG_exp\"] = (1.98722 * 298.15 * np.log(df_train[\"kd_molar\"])) / 1000.0\n",
    "df_train = df_train.drop(columns=[\"pdb_id\", \"packstat\", \"yhh_planarity\"], errors=\"ignore\").dropna()\n",
    "\n",
    "X_train = df_train.drop(columns=[\"dG_exp\", \"kd_molar\"])\n",
    "y_train = df_train[\"dG_exp\"]\n",
    "\n",
    "print(\"‚úÖ Training features shape:\", X_train.shape)\n",
    "\n",
    "# === Check each test set ===\n",
    "for name, path in test_csvs.items():\n",
    "    print(f\"\\n=== Checking {name} Test Set ===\")\n",
    "    df_test = pd.read_csv(path)\n",
    "    df_test = df_test.drop(columns=[\"description\", \"packstat\", \"yhh_planarity\"], errors=\"ignore\").dropna()\n",
    "\n",
    "    X_test = df_test.drop(columns=[\"experimental\"], errors=\"ignore\")\n",
    "    y_test = df_test[\"experimental\"]\n",
    "\n",
    "    # 1. Feature mismatch check\n",
    "    missing_in_test = set(X_train.columns) - set(X_test.columns)\n",
    "    extra_in_test = set(X_test.columns) - set(X_train.columns)\n",
    "\n",
    "    print(\" - Missing in test:\", missing_in_test)\n",
    "    print(\" - Extra in test:\", extra_in_test)\n",
    "\n",
    "    # Align columns\n",
    "    X_test_aligned = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    # 2. Scale difference check\n",
    "    train_mean = X_train.mean()\n",
    "    test_mean = X_test_aligned.mean()\n",
    "    train_std = X_train.std()\n",
    "    test_std = X_test_aligned.std()\n",
    "\n",
    "    scale_diff = pd.DataFrame({\n",
    "        \"Train Mean\": train_mean,\n",
    "        \"Test Mean\": test_mean,\n",
    "        \"Train Std\": train_std,\n",
    "        \"Test Std\": test_std\n",
    "    })\n",
    "    large_diff = scale_diff[(abs(scale_diff[\"Train Mean\"] - scale_diff[\"Test Mean\"]) > train_std)]\n",
    "    if not large_diff.empty:\n",
    "        print(\"‚ö†Ô∏è Large mean differences found in these features:\\n\", large_diff)\n",
    "\n",
    "    # 3. Try scaling both train and test to see if it helps\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test_aligned)\n",
    "\n",
    "    print(\" - Scaled data example (train first row):\", X_train_scaled[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Model Equation (preview of 10 largest |coeff| terms):\n",
      "dG_pred ‚âà -0.822032 + (18353.028350)*dslf_fa13 + (18352.970864)*fa_intra_rep + (18352.932491)*hbond_bb_sc + (18352.925315)*hbond_sr_bb + (18352.920074)*hbond_lr_bb + (18352.903419)*lk_ball_wtd + (18352.900529)*omega + (18352.897592)*p_aa_pp + (-18352.885636)*total_score + (18352.885404)*hbond_sc\n",
      "\n",
      "üìù Full equation saved to: /Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/linear_regression_model_equation.txt\n",
      "\n",
      "Contini ‚Äî first 5 predictions:\n",
      "structure_id  y_true_experimental  y_pred_linear_regression\n",
      "        1acb               -13.05                -10.514755\n",
      "        1avx               -12.50               -133.108812\n",
      "        1ay7               -13.23                -11.039989\n",
      "        1bvn               -15.06               -134.118905\n",
      "        1emv               -18.58                -32.579595\n",
      "üìÑ Saved per-structure predictions to: /Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/linear_regression_predictions_Contini.csv\n",
      "\n",
      "Nanobody ‚Äî first 5 predictions:\n",
      "structure_id  y_true_experimental  y_pred_linear_regression\n",
      "        1bzq               -10.17                -44.934661\n",
      "        1op9               -12.17                  7.169787\n",
      "        1ri8               -11.65                -10.982169\n",
      "        1rjc               -13.80                  6.991644\n",
      "        1zv5               -10.91                -11.327903\n",
      "üìÑ Saved per-structure predictions to: /Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/linear_regression_predictions_Nanobody.csv\n",
      "\n",
      "PDBbind ‚Äî first 5 predictions:\n",
      "structure_id  y_true_experimental  y_pred_linear_regression\n",
      "        2wh6               -10.50                  9.149961\n",
      "        2wp3                -8.31                 -9.187459\n",
      "        3wqb               -11.92                  4.828630\n",
      "        4b1y                -8.95                -26.781890\n",
      "        4cj0                -9.55                 27.579363\n",
      "üìÑ Saved per-structure predictions to: /Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/linear_regression_predictions_PDBbind.csv\n",
      "\n",
      "Linear Regression Baseline Performance:\n",
      "Test Set    MAE   RMSE      R       R¬≤\n",
      " Contini 40.028 65.998  0.385 -495.587\n",
      "Nanobody 14.990 21.260 -0.236 -139.487\n",
      " PDBbind 12.541 16.174  0.127  -72.646\n",
      "\n",
      "‚úÖ Results saved to 'linear_regression_baseline_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= User Paths =========\n",
    "train_csv = \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/Rueben_504.csv\"\n",
    "\n",
    "test_csvs = {\n",
    "    \"Contini\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/Contini_20_testset.csv\",\n",
    "    \"Nanobody\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/nanobody_testset.csv\",\n",
    "    \"PDBbind\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/PDBbind_testset.csv\"\n",
    "}\n",
    "# ==============================\n",
    "\n",
    "# Helper: choose an identifier column to keep for per-structure outputs\n",
    "CANDIDATE_ID_COLS = [\"pdb_id\", \"description\", \"Structure\", \"structure\",\n",
    "                     \"complex_id\", \"complex\", \"name\", \"id\"]\n",
    "\n",
    "def pick_id_col(df):\n",
    "    for c in CANDIDATE_ID_COLS:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Prepare training data (convert kd_molar to ŒîG, drop NaNs and unwanted columns)\n",
    "def prepare_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # Convert Kd (M) to ŒîG in kcal/mol\n",
    "    df[\"dG_exp\"] = (1.98722 * 298.15 * np.log(df[\"kd_molar\"])) / 1000.0\n",
    "    # Drop unwanted columns\n",
    "    drop_cols = [\"pdb_id\", \"packstat\", \"yhh_planarity\"]\n",
    "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    # Remove rows with NaNs\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Prepare test data (keep potential ID column for reporting; drop NaNs and unwanted columns)\n",
    "def prepare_test_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # Keep everything for now (so we can preserve an ID column), then drop only the known junk\n",
    "    drop_cols = [\"packstat\", \"yhh_planarity\"]  # keep 'description' if present for IDs\n",
    "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    # Remove rows with NaNs\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# === Load & prepare training data ===\n",
    "df_train = prepare_train_data(train_csv)\n",
    "X_train = df_train.drop(columns=[\"dG_exp\", \"kd_molar\"])\n",
    "y_train = df_train[\"dG_exp\"]\n",
    "\n",
    "# === Train Linear Regression model ===\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# === Show model equation ===\n",
    "feature_names = X_train.columns\n",
    "intercept = lr.intercept_\n",
    "coefs = lr.coef_\n",
    "\n",
    "# Full equation string\n",
    "equation_terms = [f\"({coef:.6f})*{name}\" for coef, name in zip(coefs, feature_names)]\n",
    "equation_full = \"dG_pred = {:.6f} + \".format(intercept) + \" + \".join(equation_terms)\n",
    "\n",
    "# Preview: top-10 terms by absolute coefficient magnitude\n",
    "top_idx = np.argsort(np.abs(coefs))[::-1][:10]\n",
    "top_terms = [f\"({coefs[i]:.6f})*{feature_names[i]}\" for i in top_idx]\n",
    "equation_preview = \"dG_pred ‚âà {:.6f} + \".format(intercept) + \" + \".join(top_terms)\n",
    "\n",
    "print(\"\\nLinear Regression Model Equation (preview of 10 largest |coeff| terms):\")\n",
    "print(equation_preview)\n",
    "\n",
    "# Save full equation to a text file alongside the training CSV\n",
    "out_dir = Path(train_csv).parent\n",
    "eq_path = out_dir / \"linear_regression_model_equation.txt\"\n",
    "with open(eq_path, \"w\") as f:\n",
    "    f.write(equation_full + \"\\n\")\n",
    "print(f\"\\nüìù Full equation saved to: {eq_path}\")\n",
    "\n",
    "# === Evaluate on each test set and save per-structure predictions ===\n",
    "results = []\n",
    "for name, path in test_csvs.items():\n",
    "    df_test = prepare_test_data(path)\n",
    "\n",
    "    id_col = pick_id_col(df_test)\n",
    "    # Build X_test by removing non-feature columns\n",
    "    non_feature_cols = [\"experimental\"]\n",
    "    if id_col:\n",
    "        non_feature_cols.append(id_col)\n",
    "    X_test = df_test.drop(columns=non_feature_cols, errors=\"ignore\")\n",
    "\n",
    "    # Align test features with training features (in case of column mismatch)\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    y_test = df_test[\"experimental\"].astype(float).values\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r, _ = pearsonr(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Test Set\": name,\n",
    "        \"MAE\": round(mae, 3),\n",
    "        \"RMSE\": round(rmse, 3),\n",
    "        \"R\": round(r, 3),\n",
    "        \"R¬≤\": round(r2, 3)\n",
    "    })\n",
    "\n",
    "    # === Per-structure predictions DataFrame ===\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"structure_id\": df_test[id_col] if id_col else np.arange(len(df_test)),\n",
    "        \"y_true_experimental\": y_test,\n",
    "        \"y_pred_linear_regression\": y_pred\n",
    "    })\n",
    "\n",
    "    # Save per-structure predictions next to the test CSV\n",
    "    pred_out = Path(path).parent / f\"linear_regression_predictions_{name}.csv\"\n",
    "    preds_df.to_csv(pred_out, index=False)\n",
    "\n",
    "    print(f\"\\n{name} ‚Äî first 5 predictions:\")\n",
    "    print(preds_df.head().to_string(index=False))\n",
    "    print(f\"üìÑ Saved per-structure predictions to: {pred_out}\")\n",
    "\n",
    "# === Show summary results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nLinear Regression Baseline Performance:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# === Save summary results ===\n",
    "summary_path = Path(train_csv).parent / \"/Users/qingshuzhao/Library/CloudStorage/OneDrive-SharedLibraries-UWM/Arjun Saha - qingshu_project/Rosetta_derived_feature_ANN/CTC_Revision/Linear_regression_prediction/linear_regression_baseline_results.csv\"\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\n‚úÖ Results saved to '{summary_path.name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictor (from training dG_exp): -9.647 kcal/mol\n",
      "\n",
      "Mean Predictor Baseline Performance:\n",
      "Test Set   MAE  RMSE   R     R¬≤  n  Mean_dG_used\n",
      " Contini 3.124 3.795 NaN -0.642 20        -9.647\n",
      "Nanobody 2.237 2.542 NaN -1.009 37        -9.647\n",
      " PDBbind 1.552 1.943 NaN -0.063 45        -9.647\n",
      "\n",
      "‚úÖ Results saved to '/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/mean_baseline_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/qingshuzhao/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ========= User Paths =========\n",
    "train_csv = \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/Rueben_504.csv\"\n",
    "\n",
    "test_csvs = {\n",
    "    \"Contini\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/Contini_20_testset.csv\",\n",
    "    \"Nanobody\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/nanobody_testset.csv\",\n",
    "    \"PDBbind\": \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/validation_set/PDBbind_testset.csv\"\n",
    "}\n",
    "out_csv = \"/Users/qingshuzhao/Downloads/PPSUS-main/binding_energy_experiments/data/mean_baseline_results.csv\"\n",
    "# ==============================\n",
    "\n",
    "# Prepare training data (convert kd_molar to ŒîG, drop NaNs and unwanted columns)\n",
    "def prepare_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # Convert Kd (M) to ŒîG in kcal/mol\n",
    "    df[\"dG_exp\"] = (1.98722 * 298.15 * np.log(df[\"kd_molar\"])) / 1000.0\n",
    "    # Drop unwanted columns\n",
    "    drop_cols = [\"pdb_id\", \"packstat\", \"yhh_planarity\"]\n",
    "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    # Remove rows with NaNs\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Prepare test data (use existing experimental column, drop NaNs and unwanted columns)\n",
    "def prepare_test_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    drop_cols = [\"description\", \"packstat\", \"yhh_planarity\"]\n",
    "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    df = df.dropna(subset=[\"experimental\"])  # ensure targets present\n",
    "    return df\n",
    "\n",
    "# === Load & prepare training data ===\n",
    "df_train = prepare_train_data(train_csv)\n",
    "y_train = df_train[\"dG_exp\"].values.astype(float)\n",
    "\n",
    "# === Mean predictor value (training mean) ===\n",
    "mean_dG = float(np.mean(y_train))\n",
    "print(f\"Mean predictor (from training dG_exp): {mean_dG:.3f} kcal/mol\")\n",
    "\n",
    "# === Evaluate on each test set ===\n",
    "rows = []\n",
    "for name, path in test_csvs.items():\n",
    "    df_test = prepare_test_data(path)\n",
    "    y_test = df_test[\"experimental\"].values.astype(float)\n",
    "\n",
    "    # Predict the same mean for every test example\n",
    "    y_pred = np.full_like(y_test, fill_value=mean_dG, dtype=float)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    # Pearson R is undefined for a constant predictor; report NaN\n",
    "    r = np.nan\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    rows.append({\n",
    "        \"Test Set\": name,\n",
    "        \"MAE\": round(mae, 3),\n",
    "        \"RMSE\": round(rmse, 3),\n",
    "        \"R\": r,             # intentionally NaN for constant predictions\n",
    "        \"R¬≤\": round(r2, 3),\n",
    "        \"n\": len(y_test),\n",
    "        \"Mean_dG_used\": round(mean_dG, 3),\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "print(\"\\nMean Predictor Baseline Performance:\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results.to_csv(out_csv, index=False)\n",
    "print(f\"\\n‚úÖ Results saved to '{out_csv}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R¬≤ score between experimental and ANN_PREDICTED: -1.6228895206387022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# === Load the CSV file ===\n",
    "file_path = \"/Users/qingshuzhao/Library/CloudStorage/OneDrive-SharedLibraries-UWM/Arjun Saha - qingshu_project/Rosetta_derived_feature_ANN/CTC_Revision/crystal_AF.csv\"   # update path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# === Extract experimental and predicted values ===\n",
    "y_true = df[\"exp.dG\"]\n",
    "y_pred = df[\"pred.dG on predicted structure\"]\n",
    "\n",
    "# === Compute R¬≤ score ===\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"R¬≤ score between experimental and ANN_PREDICTED:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
